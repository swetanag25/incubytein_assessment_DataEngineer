{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bd70c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing pyspark Libraries \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import date_add,to_date,col,exp\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e912be31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SparkSession from builder\n",
    "spark=SparkSession.builder.appName('Incubytein_Assessment').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "914c8485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- VaccinationType: string (nullable = true)\n",
      " |-- VaccinationDate: date (nullable = true)\n",
      " |-- CountryName: string (nullable = false)\n",
      "\n",
      "+---+----+---------------+---------------+-----------+\n",
      "| ID|Name|VaccinationType|VaccinationDate|CountryName|\n",
      "+---+----+---------------+---------------+-----------+\n",
      "|  1| Sam|            EFG|     2022-06-15|        USA|\n",
      "|  2|John|            XYZ|     2022-01-05|        USA|\n",
      "|  3|Mike|            ABC|     2021-12-28|        USA|\n",
      "+---+----+---------------+---------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create Dataframe to read USA.csv file\n",
    "try:\n",
    "    df_usa=(spark.read.option(\"badRecords\",\"incorrect data\")\\\n",
    "                 .csv('USA.csv',header=\"true\"))\n",
    "    df_USA_with_date=df_usa.withColumn('VaccinationDate',to_date(col('VaccinationDate').cast(\"string\"),'MMddyyyy'))\n",
    "    df_USA_correct_data=df_USA_with_date.withColumn('CountryName',lit(\"USA\"))\n",
    "    df_USA_correct_data.printSchema()\n",
    "    df_USA_correct_data.show()\n",
    "except Exception as e:\n",
    "    print('load failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80cc7a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- DOB: string (nullable = true)\n",
      " |-- VaccinationType: string (nullable = true)\n",
      " |-- VaccinationDate: string (nullable = true)\n",
      " |-- Free or Paid: string (nullable = true)\n",
      " |-- CountryName: string (nullable = false)\n",
      "\n",
      "+---+------+----------+---------------+---------------+------------+-----------+\n",
      "| ID|  Name|       DOB|VaccinationType|VaccinationDate|Free or Paid|CountryName|\n",
      "+---+------+----------+---------------+---------------+------------+-----------+\n",
      "|  1| Vikas|1998-12-01|            XYZ|     2022-01-01|           F|        IND|\n",
      "|  2| Rahul|1982-08-13|            ABC|     2022-03-05|           P|        IND|\n",
      "|  3|Sameer|1952-08-13|            ABC|     2022-02-20|           F|        IND|\n",
      "+---+------+----------+---------------+---------------+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create Dataframe to read IND.csv file\n",
    "try:\n",
    "    df_IND=(spark.read.option(\"badRecords\",\"incorrect data\")\\\n",
    "                 .csv('IND.csv',header=\"true\"))\n",
    "    #Add CountryName\n",
    "    df_IND=df_IND.withColumn('CountryName',lit(\"IND\"))\n",
    "    df_IND.printSchema()\n",
    "    df_IND.show()\n",
    "except Exception as e:\n",
    "    print('load failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a742c5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- VaccinationType: string (nullable = true)\n",
      " |-- DOB: string (nullable = true)\n",
      " |-- VaccinationDate: date (nullable = true)\n",
      " |-- CountryName: string (nullable = false)\n",
      "\n",
      "+---+---------+---------------+----------+---------------+-----------+\n",
      "| ID|     Name|VaccinationType|       DOB|VaccinationDate|CountryName|\n",
      "+---+---------+---------------+----------+---------------+-----------+\n",
      "|  1|     Mike|            LMN|      null|     2022-05-11|        AUS|\n",
      "|  2|Jonnathan|            XYZ|1997-12-13|           null|        AUS|\n",
      "|  3| Cristina|            ABC|1998-03-12|     2022-03-12|        AUS|\n",
      "+---+---------+---------------+----------+---------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create Dataframe to read AUS.xlsx file\n",
    "try:\n",
    "    df_read_excel = pd.read_excel('AUS.xlsx')\n",
    "    #convert excel to csv\n",
    "    df_to_csv=df_read_excel.to_csv (r'AUS.csv', index = None, header=True)  \n",
    "    df_AUS=(spark.read.option(\"badRecords\",\"incorrect data\")\\\n",
    "                 .csv('AUS.csv',header=\"true\"))\n",
    "    #To Format Date function \n",
    "    df_AUS_Vaccinationdate=df_AUS.withColumn('Date of Vaccination',to_date(col('Date of Vaccination').cast(\"date\"),'MM-dd-yyyy'))\n",
    "    #Add CountryName\n",
    "    df_AUS_CountryName=df_AUS_Vaccinationdate.withColumn('CountryName',lit(\"AUS\"))\n",
    "    #Rename columnn\n",
    "    df_AUS_correct_data=df_AUS_CountryName.withColumnRenamed('Unique ID','ID')\\\n",
    "                  .withColumnRenamed('Patient Name','Name')\\\n",
    "                  .withColumnRenamed('Vaccine Type','VaccinationType')\\\n",
    "                  .withColumnRenamed('Date of Birth','DOB')\\\n",
    "                  .withColumnRenamed('Date of Vaccination','VaccinationDate')\n",
    "    df_AUS_correct_data.printSchema()\n",
    "    df_AUS_correct_data.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print('load failed')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c38fd512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---------------+---------------+-----------+----------+------------+\n",
      "| ID|     Name|VaccinationType|VaccinationDate|CountryName|       DOB|Free or Paid|\n",
      "+---+---------+---------------+---------------+-----------+----------+------------+\n",
      "|  1|     Mike|            LMN|     2022-05-11|        AUS|      null|        null|\n",
      "|  2|Jonnathan|            XYZ|           null|        AUS|1997-12-13|        null|\n",
      "|  1|      Sam|            EFG|     2022-06-15|        USA|      null|        null|\n",
      "|  1|    Vikas|            XYZ|     2022-01-01|        IND|1998-12-01|           F|\n",
      "|  2|     John|            XYZ|     2022-01-05|        USA|      null|        null|\n",
      "|  2|    Rahul|            ABC|     2022-03-05|        IND|1982-08-13|           P|\n",
      "|  3|     Mike|            ABC|     2021-12-28|        USA|      null|        null|\n",
      "|  3| Cristina|            ABC|     2022-03-12|        AUS|1998-03-12|        null|\n",
      "|  3|   Sameer|            ABC|     2022-02-20|        IND|1952-08-13|           F|\n",
      "+---+---------+---------------+---------------+-----------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Join IND and USA dataframe\n",
    "df_USA_IND=df_USA_correct_data.join(df_IND,on=[\"ID\",\"Name\",\"VaccinationType\",\"VaccinationDate\",\"CountryName\"],how='Outer')\n",
    "\n",
    "#Join AUS and df_USA_IND dataframe\n",
    "df_merge_country=df_AUS_correct_data.join(df_USA_IND,on=[\"ID\",\"Name\",\"VaccinationType\",\"VaccinationDate\",\"CountryName\",\"DOB\"],how='outer')\n",
    "df_merge_country.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "935f0ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---------------+---------------+-----------+----------+------------+\n",
      "| ID|    Name|VaccinationType|VaccinationDate|CountryName|       DOB|Free or Paid|\n",
      "+---+--------+---------------+---------------+-----------+----------+------------+\n",
      "|  1|    Mike|            LMN|     2022-05-11|        AUS|      null|        null|\n",
      "|  1|     Sam|            EFG|     2022-06-15|        USA|      null|        null|\n",
      "|  1|   Vikas|            XYZ|     2022-01-01|        IND|1998-12-01|           F|\n",
      "|  2|    John|            XYZ|     2022-01-05|        USA|      null|        null|\n",
      "|  2|   Rahul|            ABC|     2022-03-05|        IND|1982-08-13|           P|\n",
      "|  3|    Mike|            ABC|     2021-12-28|        USA|      null|        null|\n",
      "|  3|Cristina|            ABC|     2022-03-12|        AUS|1998-03-12|        null|\n",
      "|  3|  Sameer|            ABC|     2022-02-20|        IND|1952-08-13|           F|\n",
      "+---+--------+---------------+---------------+-----------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#drop Null value for Vaccination date\n",
    "sdf_merge_country=df_merge_country.na.drop(how='any',subset=['VaccinationDate'])\n",
    "sdf_merge_country.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad5223af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---------------+---------------+-----------+----------+------------+\n",
      "| Id|    Name|VaccinationType|VaccinationDate|CountryName|       DOB|Free or Paid|\n",
      "+---+--------+---------------+---------------+-----------+----------+------------+\n",
      "|  0|    Mike|            LMN|     2022-05-11|        AUS|      null|        null|\n",
      "|  1|     Sam|            EFG|     2022-06-15|        USA|      null|        null|\n",
      "|  2|   Vikas|            XYZ|     2022-01-01|        IND|1998-12-01|           F|\n",
      "|  3|    John|            XYZ|     2022-01-05|        USA|      null|        null|\n",
      "|  4|   Rahul|            ABC|     2022-03-05|        IND|1982-08-13|           P|\n",
      "|  5|    Mike|            ABC|     2021-12-28|        USA|      null|        null|\n",
      "|  6|Cristina|            ABC|     2022-03-12|        AUS|1998-03-12|        null|\n",
      "|  7|  Sameer|            ABC|     2022-02-20|        IND|1952-08-13|           F|\n",
      "+---+--------+---------------+---------------+-----------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Assigning unique id to dataframe\n",
    "df_unique=sdf_merge_country.withColumn(\"Id\",monotonically_increasing_id())\n",
    "df_unique.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba7ff04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total vaccination count by countryname and vaccination type\n",
    "from pyspark.sql.functions import countDistinct\n",
    "Total_Vaccincation=df_unique.select(\"CountryName\", \"VaccinationType\").count()\n",
    "Total_Vaccincation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a62c386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------------------+\n",
      "|CountryName|VaccinationType|No. of vaccinations|\n",
      "+-----------+---------------+-------------------+\n",
      "|        AUS|            ABC|                  1|\n",
      "|        IND|            ABC|                  2|\n",
      "|        USA|            XYZ|                  1|\n",
      "|        AUS|            LMN|                  1|\n",
      "|        IND|            XYZ|                  1|\n",
      "|        USA|            EFG|                  1|\n",
      "|        USA|            ABC|                  1|\n",
      "+-----------+---------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#CountryName, VaccinationType, No. of vaccinations\n",
    "df_count_vaccination=df_unique.groupby(\"CountryName\",\"VaccinationType\").count()\n",
    "df_metric1=df_count_vaccination.withColumnRenamed('count','No. of vaccinations')\n",
    "df_metric1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60c5f3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+\n",
      "|CountryName|% Vaccinated|\n",
      "+-----------+------------+\n",
      "|        AUS|         0.1|\n",
      "|        USA|        0.15|\n",
      "|        IND|        0.15|\n",
      "+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculating % vaccination in each country \n",
    "df_each_country=df_unique.groupby(\"CountryName\").count()\n",
    "#taking population as 2000\n",
    "total_population=2000\n",
    "per_each_country=df_each_country.withColumn('% Vaccinated',(df_each_country[\"count\"]/total_population)*100)\n",
    "df_metric2=per_each_country.drop(\"count\")\n",
    "df_metric2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74f877c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n"
     ]
    }
   ],
   "source": [
    "#Calculate total contribution \n",
    "total_contribution=df_metric2.agg({'% Vaccinated':'sum'}).collect()[0][0]\n",
    "print(total_contribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8630fc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|CountryName|   % contribution|\n",
      "+-----------+-----------------+\n",
      "|        AUS|             25.0|\n",
      "|        USA|37.49999999999999|\n",
      "|        IND|37.49999999999999|\n",
      "+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculating % vaccination contribution by country \n",
    "Percentage_of_contribution=df_metric2.withColumn('% contribution',(df_metric2[\"% Vaccinated\"]/total_contribution)*100)\n",
    "df_metric3=Percentage_of_contribution.drop(\"% Vaccinated\")\n",
    "df_metric3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ffbbe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260cff0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
